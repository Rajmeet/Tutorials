{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "## Introduction\n",
    "Imagine you have to pull a large amount of data from websites and you want to do it as quickly as possible. The only possible way is <b>Web Scraping.</b> <br>\n",
    "Web scraping is an automated method used to extract large amounts of data from websites. The data on the websites are unstructured. Web scraping helps collect these unstructured data and store it in a structured form.\n",
    "\n",
    "## Why Web Scraping?\n",
    "Web scraping is used to collect large information from websites. But why does someone have to collect such large data from websites? To know about this, let’s look at the applications of web scraping:\n",
    "<ol>\n",
    "<li>Price Comparison: To collect data from online shopping websites and use it to compare the prices of products.\n",
    "    </li>\n",
    "<li>\n",
    "Email address gathering: Many companies that use email as a medium for marketing, use web scraping to collect email ID and then send bulk emails.\n",
    "    </li>\n",
    "<li>\n",
    "Social Media Scraping: Web scraping is used to collect data from Social Media websites such as Twitter to find out what’s trending.\n",
    "    </li>\n",
    "<li>    \n",
    "Job listings: Details regarding job openings, interviews are collected from different websites and then listed in one place so that it is easily accessible to the user.\n",
    "    </li>\n",
    "</ol>\n",
    "\n",
    "## How does Web Scraping Work?\n",
    "1. First the client sends a request to the website which needs to be scraped\n",
    "2. The website responds to the request by returning HTML AND XML files\n",
    "3. The client then tries to find the extractable data.\n",
    "4. This data can now be stored in an csv or excel file.\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procedure\n",
    "\n",
    "## Python Libraries for Web Scraping\n",
    "1. Selenium - Website automation\n",
    "2. BeautifulSoup - Parsing HTML and XML files\n",
    "3. Pandas - Analysis\n",
    "\n",
    "## Analysing the Website\n",
    "The first and the foremost step is to get familiar with what you are going to scrape.\n",
    "Here, I am going to scrape an Online Shopping Website - FlipKart for Laptop.\n",
    "For analysing the website I am going to be using <b>Inspect Element</b>.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
